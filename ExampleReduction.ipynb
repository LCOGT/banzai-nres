{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guide: Be in banzai-nres root folder before starting to run this ipynb.\n",
    "\n",
    "Run each cell sequentially and wait for each cell to finish before running the next one.\n",
    "\n",
    "If you have already run this notebook once then you should have a test.db created etc. If you close the notebook, you can resume where you left off without rerunning all the stages: simple run all the cells that are marked with a #QUICK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "import os\n",
    "banzai_nres_path = os.getcwd()\n",
    "banzai_nres_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "os.environ['OPENTSDB_PYTHON_METRICS_TEST_MODE'] = 'True'\n",
    "os.environ['DB_ADDRESS'] = 'sqlite:///test.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "import banzai\n",
    "from banzai.logs import set_log_level\n",
    "set_log_level('DEBUG')\n",
    "import logging\n",
    "logger = logging.getLogger('banzai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for the test dataset.\n",
    "raw_data_dir = 'test_data/lsc/nres01/20180313/raw'\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "bpm_dir = 'test_data/lsc/nres01/bpm/'\n",
    "os.makedirs(bpm_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which files we will download for our test dataset.\n",
    "bpm_filename = 'bpm-lsc-nres01-fl09-20180215.fits.fz'\n",
    "test_filenames = ['lscnrs01-fl09-20180313-0001-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0002-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0003-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0004-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0005-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0006-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0007-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0008-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0009-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0010-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0011-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0012-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0013-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0014-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0015-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0016-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0017-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0018-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0019-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0020-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0021-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0022-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0023-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0042-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0043-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0044-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0045-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0046-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0047-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0048-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0049-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0028-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0029-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0030-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0031-e00.fits.fz']\n",
    "\n",
    "bpm_frame_id = '22529799'\n",
    "test_frame_ids = ['8148793',\n",
    "                  '8148822',\n",
    "                  '8148805',\n",
    "                  '8148824',\n",
    "                  '8148826',\n",
    "                  '8148876',\n",
    "                  '8148898',\n",
    "                  '8148932',\n",
    "                  '8148960',\n",
    "                  '8148978',\n",
    "                  '8149024',\n",
    "                  '8149104',\n",
    "                  '8149068',\n",
    "                  '8149090',\n",
    "                  '8149128',\n",
    "                  '8149173',\n",
    "                  '8149217',\n",
    "                  '8151252',\n",
    "                  '8149314',\n",
    "                  '8149388',\n",
    "                  '8149469',\n",
    "                  '8149547',\n",
    "                  '8149570',\n",
    "                  '8156341',\n",
    "                  '8156360',\n",
    "                  '8156366',\n",
    "                  '8156376',\n",
    "                  '8156385',\n",
    "                  '8156433',\n",
    "                  '8156500',\n",
    "                  '8156560',\n",
    "                  '8151997',\n",
    "                  '8152050',\n",
    "                  '8152110',\n",
    "                  '8152153']\n",
    "DAYS_OBS = ['lsc/nres01/20180313']\n",
    "INSTRUMENTS = ['lsc/nres01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Copy the data into the correct directory\n",
    "for test_filename, frame_id in zip(test_filenames, test_frame_ids):\n",
    "    archive_url = f'https://archive-api.lco.global/frames/{frame_id}'\n",
    "    frame_info = requests.get(archive_url).json()\n",
    "    with open(os.path.join(raw_data_dir, test_filename), 'wb') as f:\n",
    "        f.write(requests.get(frame_info['url']).content)\n",
    "        \n",
    "archive_url = f'https://archive-api.lco.global/frames/{bpm_frame_id}'\n",
    "frame_info = requests.get(archive_url).json()\n",
    "with open(os.path.join(bpm_dir, bpm_filename), 'wb') as f:\n",
    "    f.write(requests.get(frame_info['url']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "os.chdir('test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "from banzai_nres import settings\n",
    "settings.processed_path= os.getcwd()\n",
    "settings.fpack=True\n",
    "settings.db_address = os.environ['DB_ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "import argparse\n",
    "from banzai.context import Context\n",
    "from banzai.main import add_settings_to_context\n",
    "def parse_args(settings, extra_console_arguments=None, parser_description='Process LCO data.'):\n",
    "    \"\"\"Parse arguments, including default command line argument, and set the overall log level\"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=parser_description)\n",
    "\n",
    "    parser.add_argument(\"--processed-path\", default='/archive/engineering',\n",
    "                        help='Top level directory where the processed data will be stored')\n",
    "    parser.add_argument(\"--log-level\", default='info', choices=['debug', 'info', 'warning',\n",
    "                                                                'critical', 'fatal', 'error'])\n",
    "    parser.add_argument('--post-to-archive', dest='post_to_archive', action='store_true', default=False)\n",
    "    parser.add_argument('--no-file-cache', dest='no_file_cache', action='store_true', default=False,\n",
    "                        help='Turn off saving files to disk')\n",
    "    parser.add_argument('--post-to-elasticsearch', dest='post_to_elasticsearch', action='store_true',\n",
    "                        default=False)\n",
    "    parser.add_argument('--fpack', dest='fpack', action='store_true', default=False,\n",
    "                        help='Fpack the output files?')\n",
    "    parser.add_argument('--override-missing-calibrations', dest='override_missing', action='store_true', default=False,\n",
    "                        help='Continue processing a file even if a master calibration does not exist?')\n",
    "    parser.add_argument('--rlevel', dest='reduction_level', default=91, type=int, help='Reduction level')\n",
    "    parser.add_argument('--db-address', dest='db_address',\n",
    "                        default='mysql://cmccully:password@localhost/test',\n",
    "                        help='Database address: Should be in SQLAlchemy form')\n",
    "    parser.add_argument('--elasticsearch-url', dest='elasticsearch_url',\n",
    "                        default='http://elasticsearch.lco.gtn:9200')\n",
    "    parser.add_argument('--es-index', dest='elasticsearch_qc_index', default='banzai_qc',\n",
    "                        help='ElasticSearch index to use for QC results')\n",
    "    parser.add_argument('--es-doc-type', dest='elasticsearch_doc_type', default='qc',\n",
    "                        help='Elasticsearch document type for QC records')\n",
    "    parser.add_argument('--no-bpm', dest='no_bpm', default=False, action='store_true',\n",
    "                        help='Do not use a bad pixel mask to reduce data (BPM contains all zeros)')\n",
    "    parser.add_argument('--use-only-older-calibrations', dest='use_only_older_calibrations', default=False,\n",
    "                        action='store_true', help='Only use calibrations that were created before the start of the block')\n",
    "    parser.add_argument('--preview-mode', dest='preview_mode', default=False, action='store_true',\n",
    "                        help='Save the reductions to the preview directory')\n",
    "    parser.add_argument('--max-tries', dest='max_tries', default=5,\n",
    "                        help='Maximum number of times to try to process a frame')\n",
    "    parser.add_argument('--broker-url', dest='broker_url',\n",
    "                        help='URL for the FITS broker service.')\n",
    "\n",
    "    if extra_console_arguments is None:\n",
    "        extra_console_arguments = []\n",
    "    for argument in extra_console_arguments:\n",
    "        parser.add_argument(*argument['args'], **argument['kwargs'])\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    add_settings_to_context(args, settings)\n",
    "    return Context(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "from glob import glob\n",
    "# set up the context object.\n",
    "context = parse_args(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'banzai_create_db --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site lsc --camera fl09 --name nres01 --camera-type 1m0-NRES-SciCam --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site elp --camera fl17 --name nres02 --camera-type 1m0-NRES-SciCam --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "for instrument in INSTRUMENTS:\n",
    "    for bpm_filename in glob(os.path.join(settings.processed_path, instrument, 'bpm/*bpm*')):\n",
    "        logger.info(f'adding bpm {bpm_filename} to the database')\n",
    "        os.system(f'banzai_nres_add_bpm --filename {bpm_filename} --db-address={os.environ[\"DB_ADDRESS\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUICK!\n",
    "from banzai import dbs\n",
    "from banzai.utils.stage_utils import run_pipeline_stages\n",
    "from banzai.calibrations import make_master_calibrations\n",
    "instrument = dbs.get_instruments_at_site('lsc', settings.db_address)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_files = glob(os.path.join(settings.processed_path, '*/nres??/*/raw/*b00*'))\n",
    "for bias_file in bias_files: \n",
    "    run_pipeline_stages([{'path': bias_file}], context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_frames_as_good(raw_filenames): \n",
    "    logger.info('Marking frames as good for filenames: {filenames}'.format(filenames=raw_filenames)) \n",
    "    for day_obs in DAYS_OBS: \n",
    "        for filename in glob(os.path.join(settings.processed_path, day_obs, 'processed', raw_filenames)): \n",
    "            dbs.mark_frame(os.path.basename(filename), \"good\", db_address=os.environ['DB_ADDRESS']) \n",
    "            logger.info('Finished marking frames as good for filenames: {filenames}'.format(filenames=raw_filenames))                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually run the stages. If you have previously done the reduction in full, the below stages can be repeated in any order you want. I.e. I could choose just to run `make_master_calibrations(instrument, 'DARK', '2017-01-01', '2019-01-01', context) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_frames_as_good('*b91*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'BIAS', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_files = glob(os.path.join(settings.processed_path, '*/nres??/*/raw/*d00*'))\n",
    "for dark_file in dark_files: \n",
    "    run_pipeline_stages([{'path': dark_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_frames_as_good('*d91*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'DARK', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_files = glob(os.path.join(settings.processed_path, '*/nres??/*/raw/*w00*'))\n",
    "for flat_file in flat_files: \n",
    "    run_pipeline_stages([{'path': flat_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'LAMPFLAT', '2017-01-01', '2019-01-01', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_files = glob(os.path.join(settings.processed_path, '*/nres??/*/raw/*a00*'))\n",
    "for arc_file in arc_files: \n",
    "    run_pipeline_stages([{'path': arc_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'DOUBLE', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_files = glob(os.path.join(settings.processed_path, '*/nres??/*/raw/*e00*'))\n",
    "for science_file in science_files: \n",
    "    run_pipeline_stages([{'path': science_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
