{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENTSDB_PYTHON_METRICS_TEST_MODE'] = 'True'\n",
    "os.environ['DB_ADDRESS'] = 'sqlite:///test.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import banzai\n",
    "from banzai.logs import set_log_level\n",
    "set_log_level('DEBUG')\n",
    "import logging\n",
    "logger = logging.getLogger('banzai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = 'test_data/lsc/nres01/20180313/raw'\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "bpm_dir = 'test_data/lsc/nres01/bpm/'\n",
    "os.makedirs(bpm_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_filename = 'bpm-lsc-nres01-fl09-20180215.fits.fz'\n",
    "test_filenames = ['lscnrs01-fl09-20180313-0001-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0002-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0003-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0004-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0005-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0006-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0007-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0008-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0009-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0010-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0011-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0012-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0013-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0014-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0015-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0016-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0017-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0018-w00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0019-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0020-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0021-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0022-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0023-a00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0042-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0043-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0044-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0045-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0046-b00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0047-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0048-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0049-d00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0028-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0029-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0030-e00.fits.fz',\n",
    "                  'lscnrs01-fl09-20180313-0031-e00.fits.fz']\n",
    "\n",
    "bpm_frame_id = '22529799'\n",
    "test_frame_ids = ['8148793',\n",
    "                  '8148822',\n",
    "                  '8148805',\n",
    "                  '8148824',\n",
    "                  '8148826',\n",
    "                  '8148876',\n",
    "                  '8148898',\n",
    "                  '8148932',\n",
    "                  '8148960',\n",
    "                  '8148978',\n",
    "                  '8149024',\n",
    "                  '8149104',\n",
    "                  '8149068',\n",
    "                  '8149090',\n",
    "                  '8149128',\n",
    "                  '8149173',\n",
    "                  '8149217',\n",
    "                  '8151252',\n",
    "                  '8149314',\n",
    "                  '8149388',\n",
    "                  '8149469',\n",
    "                  '8149547',\n",
    "                  '8149570',\n",
    "                  '8156341',\n",
    "                  '8156360',\n",
    "                  '8156366',\n",
    "                  '8156376',\n",
    "                  '8156385',\n",
    "                  '8156433',\n",
    "                  '8156500',\n",
    "                  '8156560',\n",
    "                  '8151997',\n",
    "                  '8152050',\n",
    "                  '8152110',\n",
    "                  '8152153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Copy the data into the correct directory\n",
    "for test_filename, frame_id in zip(test_filenames, test_frame_ids):\n",
    "    archive_url = f'https://archive-api.lco.global/frames/{frame_id}'\n",
    "    frame_info = requests.get(archive_url).json()\n",
    "    with open(os.path.join(raw_data_dir, test_filename), 'wb') as f:\n",
    "        f.write(requests.get(frame_info['url']).content)\n",
    "        \n",
    "archive_url = f'https://archive-api.lco.global/frames/{bpm_frame_id}'\n",
    "frame_info = requests.get(archive_url).json()\n",
    "with open(os.path.join(bpm_dir, bpm_filename), 'wb') as f:\n",
    "    f.write(requests.get(frame_info['url']).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai_nres import settings\n",
    "settings.processed_path= os.getcwd()\n",
    "settings.fpack=True\n",
    "settings.db_address = os.environ['DB_ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from banzai.context import Context\n",
    "from banzai.main import add_settings_to_context\n",
    "def parse_args(settings, extra_console_arguments=None, parser_description='Process LCO data.'):\n",
    "    \"\"\"Parse arguments, including default command line argument, and set the overall log level\"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=parser_description)\n",
    "\n",
    "    parser.add_argument(\"--processed-path\", default='/archive/engineering',\n",
    "                        help='Top level directory where the processed data will be stored')\n",
    "    parser.add_argument(\"--log-level\", default='info', choices=['debug', 'info', 'warning',\n",
    "                                                                'critical', 'fatal', 'error'])\n",
    "    parser.add_argument('--post-to-archive', dest='post_to_archive', action='store_true', default=False)\n",
    "    parser.add_argument('--no-file-cache', dest='no_file_cache', action='store_true', default=False,\n",
    "                        help='Turn off saving files to disk')\n",
    "    parser.add_argument('--post-to-elasticsearch', dest='post_to_elasticsearch', action='store_true',\n",
    "                        default=False)\n",
    "    parser.add_argument('--fpack', dest='fpack', action='store_true', default=False,\n",
    "                        help='Fpack the output files?')\n",
    "    parser.add_argument('--override-missing-calibrations', dest='override_missing', action='store_true', default=False,\n",
    "                        help='Continue processing a file even if a master calibration does not exist?')\n",
    "    parser.add_argument('--rlevel', dest='reduction_level', default=91, type=int, help='Reduction level')\n",
    "    parser.add_argument('--db-address', dest='db_address',\n",
    "                        default='mysql://cmccully:password@localhost/test',\n",
    "                        help='Database address: Should be in SQLAlchemy form')\n",
    "    parser.add_argument('--elasticsearch-url', dest='elasticsearch_url',\n",
    "                        default='http://elasticsearch.lco.gtn:9200')\n",
    "    parser.add_argument('--es-index', dest='elasticsearch_qc_index', default='banzai_qc',\n",
    "                        help='ElasticSearch index to use for QC results')\n",
    "    parser.add_argument('--es-doc-type', dest='elasticsearch_doc_type', default='qc',\n",
    "                        help='Elasticsearch document type for QC records')\n",
    "    parser.add_argument('--no-bpm', dest='no_bpm', default=False, action='store_true',\n",
    "                        help='Do not use a bad pixel mask to reduce data (BPM contains all zeros)')\n",
    "    parser.add_argument('--use-only-older-calibrations', dest='use_only_older_calibrations', default=False,\n",
    "                        action='store_true', help='Only use calibrations that were created before the start of the block')\n",
    "    parser.add_argument('--preview-mode', dest='preview_mode', default=False, action='store_true',\n",
    "                        help='Save the reductions to the preview directory')\n",
    "    parser.add_argument('--max-tries', dest='max_tries', default=5,\n",
    "                        help='Maximum number of times to try to process a frame')\n",
    "    parser.add_argument('--broker-url', dest='broker_url',\n",
    "                        help='URL for the FITS broker service.')\n",
    "\n",
    "    if extra_console_arguments is None:\n",
    "        extra_console_arguments = []\n",
    "    for argument in extra_console_arguments:\n",
    "        parser.add_argument(*argument['args'], **argument['kwargs'])\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    add_settings_to_context(args, settings)\n",
    "    return Context(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = parse_args(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from banzai.celery import app, schedule_calibration_stacking\n",
    "from banzai.dbs import get_session\n",
    "import argparse\n",
    "from banzai import dbs\n",
    "from types import ModuleType\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from astropy.io import fits\n",
    "from glob import glob\n",
    "import logging\n",
    "from banzai_nres.tests.test_e2e import get_instrument_ids\n",
    "\n",
    "logger = logging.getLogger('banzai')\n",
    "\n",
    "TEST_PACKAGE = 'banzai_nres.tests'\n",
    "\n",
    "DATA_ROOT= settings.processed_path \n",
    "SITES = [os.path.basename(site_path) for site_path in glob(os.path.join(DATA_ROOT, '???'))]\n",
    "INSTRUMENTS = [os.path.join(site, os.path.basename(instrument_path)) for site in SITES\n",
    "               for instrument_path in glob(os.path.join(os.path.join(DATA_ROOT, site, '*')))]\n",
    "\n",
    "DAYS_OBS = [os.path.join(instrument, os.path.basename(dayobs_path)) for instrument in INSTRUMENTS\n",
    "            for dayobs_path in glob(os.path.join(DATA_ROOT, instrument, '201*'))]\n",
    "\n",
    "TEST_PACKAGE = 'banzai_nres.tests'\n",
    "CONFIGDB_FILENAME = get_pkg_data_filename('data/configdb_example.json', TEST_PACKAGE)\n",
    "# distinct files for the line lists for each instrument because otherwise they will not be added to the database\n",
    "# because .db entries with the same filename are marked as duplicates (see banzai.dbs.save_calibration_info()).\n",
    "LINE_LIST_FILENAMES = [get_pkg_data_filename('data/ThAr_atlas_ESO_copy0' + str(c) + '.txt', TEST_PACKAGE) for c in [1, 2, 3, 4]]\n",
    "if len(INSTRUMENTS) > len(LINE_LIST_FILENAMES):\n",
    "    logger.warning(f'Found {len(LINE_LIST_FILENAMES)} line list files')\n",
    "    logger.warning('Not enough line list txt files for all the instruments that will be added to the database!') | {\"processName\": \"MainProcess\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'banzai_create_db --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site lsc --camera fl09 --name nres01 --camera-type 1m0-NRES-SciCam --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site elp --camera fl17 --name nres02 --camera-type 1m0-NRES-SciCam --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "for instrument in INSTRUMENTS:\n",
    "    for bpm_filename in glob(os.path.join(DATA_ROOT, instrument, 'bpm/*bpm*')):\n",
    "        logger.info(f'adding bpm {bpm_filename} to the database')\n",
    "        os.system(f'banzai_nres_add_bpm --filename {bpm_filename} --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "instrument_ids = get_instrument_ids(os.environ[\"DB_ADDRESS\"], names=['nres01', 'nres02'])\n",
    "for instrument_id, line_list in zip(instrument_ids, LINE_LIST_FILENAMES[:len(instrument_ids)]):\n",
    "    logger.info(f'adding line list to the database for instrument with id {str(instrument_id)}')\n",
    "    os.system(f'banzai_nres_add_line_list --filename {line_list} --db-address={os.environ[\"DB_ADDRESS\"]} '\n",
    "              f'--instrument-id {instrument_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai.utils.stage_utils import run_pipeline_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_files = glob(os.path.join(DATA_ROOT, '*/nres??/*/raw/*b00*'))\n",
    "for bias_file in bias_files: \n",
    "    run_pipeline_stages([{'path': bias_file}], context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai import dbs\n",
    "def mark_frames_as_good(raw_filenames): \n",
    "    logger.info('Marking frames as good for filenames: {filenames}'.format(filenames=raw_filenames)) \n",
    "    for day_obs in DAYS_OBS: \n",
    "        for filename in glob(os.path.join(DATA_ROOT, day_obs, 'processed', raw_filenames)): \n",
    "            dbs.mark_frame(os.path.basename(filename), \"good\", db_address=os.environ['DB_ADDRESS']) \n",
    "            logger.info('Finished marking frames as good for filenames: {filenames}'.format(filenames=raw_filenames))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_frames_as_good('*b91*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai.calibrations import make_master_calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument = dbs.get_instruments_at_site('lsc', settings.db_address)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'BIAS', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_files = glob(os.path.join(DATA_ROOT, '*/nres??/*/raw/*d00*'))\n",
    "for dark_file in dark_files: \n",
    "    run_pipeline_stages([{'path': dark_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_frames_as_good('*d91*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'DARK', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_files = glob(os.path.join(DATA_ROOT, '*/nres??/*/raw/*w00*'))\n",
    "for flat_file in flat_files: \n",
    "    run_pipeline_stages([{'path': flat_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark_frames_as_good('*w91*')\n",
    "make_master_calibrations(instrument, 'LAMPFLAT', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_files = glob(os.path.join(DATA_ROOT, '*/nres??/*/raw/*a00*'))\n",
    "for arc_file in arc_files: \n",
    "    run_pipeline_stages([{'path': arc_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'DOUBLE', '2017-01-01', '2019-01-01', context) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_files = glob(os.path.join(DATA_ROOT, '*/nres??/*/raw/*e00*'))\n",
    "for science_file in science_files: \n",
    "    run_pipeline_stages([{'path': science_file}], context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
